# Sign Language Translator

This project is a real-time sign language translator that uses a trained deep learning model and Mediapipe for hand landmark detection. The application captures video input, detects hand landmarks, and predicts the corresponding sign language gesture.

## Features
- Real-time hand gesture detection using Mediapipe.
- Prediction of sign language gestures using a pre-trained deep learning model.
- Visual feedback with landmarks and predictions displayed on the video feed.

## Requirements
To run this project, you need the following dependencies installed:

- Python 3.7 or higher
- OpenCV
- Mediapipe
- TensorFlow/Keras
- NumPy

You can install the required libraries using the following command:
```bash
pip install opencv-python mediapipe tensorflow numpy
